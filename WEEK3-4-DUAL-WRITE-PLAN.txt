================================================================================
LA TANDA - WEEK 3-4: INLINE DUAL-WRITE IMPLEMENTATION PLAN
================================================================================
Date: 2025-11-14
Status: Week 1-2 Complete (Database Score: 1.75/2)
Objective: Implement dual-write pattern in critical endpoints
Strategy: Inline pattern (simpler than module restructuring)

================================================================================
1. WHY INLINE DUAL-WRITE APPROACH?
================================================================================

LESSONS FROM DAY 14:
- Complex module (db-unified-dualwrite.js) passed syntax check
- Runtime module loading failed with try-catch error
- Rollback to single-write version successful
- Production stability maintained (zero downtime)

INLINE BENEFITS:
+ Simpler implementation (no module restructuring)
+ Easier debugging (logic visible in endpoint code)
+ Lower risk (changes isolated to specific endpoints)
+ Faster deployment (no module swap required)
+ Better error messages (clear context)

================================================================================
2. DUAL-WRITE PATTERN TEMPLATE
================================================================================

PATTERN: Write to PostgreSQL (primary) + JSON (backup)

CODE TEMPLATE:
try {
    // STEP 1: Write to PostgreSQL (primary)
    const result = await db.createResource(data);
    log("info", "Resource created in PostgreSQL");
    
    // STEP 2: Write to JSON (backup)
    database.collection.push(result);
    saveDatabase();
    log("info", "Resource created in JSON backup");
    
    // STEP 3: Return success
    sendSuccess(res, result, { source: "dual-write" });
    
} catch (pgError) {
    // FALLBACK: PostgreSQL failed, still save to JSON
    log("error", "PostgreSQL write failed: " + pgError.message);
    
    // Create in JSON only
    const fallbackResult = { ...data, id: generateId() };
    database.collection.push(fallbackResult);
    saveDatabase();
    
    sendSuccess(res, fallbackResult, { 
        source: "json-fallback",
        warning: "PostgreSQL unavailable"
    });
}

================================================================================
3. PRIORITY ENDPOINTS FOR IMPLEMENTATION
================================================================================

PHASE 1 (Week 3, Days 1-3):
[HIGH PRIORITY - User Registration]
- POST /api/auth/register (Line ~1867)
  Traffic: HIGH
  Impact: Critical (new user creation)
  Complexity: MEDIUM

PHASE 2 (Week 3, Days 4-7):
[HIGH PRIORITY - Group Creation]
- POST /api/groups (Line ~2250)
  Traffic: MEDIUM
  Impact: Critical (core feature)
  Complexity: MEDIUM

PHASE 3 (Week 4, Days 1-3):
[MEDIUM PRIORITY - User Updates]
- PUT /api/mobile/settings (Line ~3500)
  Traffic: MEDIUM
  Impact: Important (user settings)
  Complexity: LOW

PHASE 4 (Week 4, Days 4-7):
[MEDIUM PRIORITY - Login Tracking]
- POST /api/auth/login (Line ~1851)
  Traffic: HIGH
  Impact: Important (last_access update)
  Complexity: LOW

================================================================================
4. DETAILED IMPLEMENTATION: POST /api/auth/register
================================================================================

CURRENT CODE (Line ~1867, SINGLE-WRITE):
----------------------------------------
if (pathname === '/api/auth/register' && method === 'POST') {
    const { name, email, password } = body;
    
    // Create user in JSON only
    const newUser = {
        id: generateId(),
        name,
        email,
        password: hashPassword(password),
        created_at: new Date().toISOString()
    };
    
    database.users.push(newUser);
    saveDatabase();
    
    sendSuccess(res, { user: newUser });
    return;
}

NEW CODE (DUAL-WRITE):
----------------------------------------
if (pathname === '/api/auth/register' && method === 'POST') {
    const { name, email, password } = body;
    
    try {
        // STEP 1: Create in PostgreSQL (primary)
        const userData = {
            user_id: generateId(),
            name,
            email,
            password: hashPassword(password),
            verification_level: 'basic',
            registration_date: new Date().toISOString(),
            status: 'active',
            total_contributions: 0
        };
        
        const newUser = await db.createUser(userData);
        log("info", "POST /api/auth/register: User created in PostgreSQL: " + userData.user_id);
        
        // STEP 2: Create in JSON (backup)
        database.users.push({
            id: userData.user_id,
            name: userData.name,
            email: userData.email,
            password: userData.password,
            created_at: userData.registration_date
        });
        saveDatabase();
        log("info", "POST /api/auth/register: User created in JSON backup: " + userData.user_id);
        
        // STEP 3: Return success
        sendSuccess(res, { 
            user: newUser,
            source: "dual-write"
        });
        
    } catch (pgError) {
        // FALLBACK: PostgreSQL failed, still create in JSON
        log("error", "POST /api/auth/register PostgreSQL error: " + pgError.message);
        
        const fallbackUser = {
            id: generateId(),
            name,
            email,
            password: hashPassword(password),
            created_at: new Date().toISOString()
        };
        
        database.users.push(fallbackUser);
        saveDatabase();
        
        sendSuccess(res, { 
            user: fallbackUser,
            source: "json-fallback",
            warning: "PostgreSQL unavailable, using backup"
        });
    }
    return;
}

================================================================================
5. STEP-BY-STEP IMPLEMENTATION GUIDE
================================================================================

DAY 1: POST /api/auth/register
-------------------------------
1. Backup current API file:
   cp integrated-api-complete-95-endpoints.js integrated-api-complete-95-endpoints.BACKUP-BEFORE-DUALWRITE-REGISTER

2. Locate endpoint code (line ~1867):
   grep -n "POST.*api/auth/register" integrated-api-complete-95-endpoints.js

3. Apply dual-write pattern (see template above)

4. Test registration:
   curl -X POST http://localhost:3002/api/auth/register \
     -H "Content-Type: application/json" \
     -d '{"name":"Test User","email":"test@example.com","password":"test123"}'

5. Validate both databases:
   - PostgreSQL: SELECT * FROM users WHERE email = 'test@example.com';
   - JSON: grep "test@example.com" /var/www/api.latanda.online/database.json

6. Monitor logs:
   pm2 logs latanda-api-fixed --lines 50

7. If successful, continue to next endpoint
   If failed, rollback and debug

DAY 2-3: POST /api/groups
--------------------------
[Repeat same steps for POST /api/groups endpoint]

DAY 4-5: Data Consistency Validation
-------------------------------------
Create validation script (see section 6 below)

DAY 6-7: Monitoring Setup
--------------------------
Setup PostgreSQL slow query logging (see section 7 below)

================================================================================
6. DATA CONSISTENCY VALIDATION SCRIPT
================================================================================

SCRIPT: /var/www/html/main/validate-sync.js
-------------------------------------------
const { Client } = require('pg');
const fs = require('fs');

const pgClient = new Client({
    host: 'localhost',
    port: 5432,
    database: 'latanda_production',
    user: 'postgres',
    password: 'latanda123'
});

async function validateSync() {
    console.log('=== DATA CONSISTENCY VALIDATION ===');
    
    // Connect to PostgreSQL
    await pgClient.connect();
    
    // Load JSON database
    const jsonDb = JSON.parse(fs.readFileSync('/var/www/api.latanda.online/database.json', 'utf8'));
    
    // Validate Users
    const pgUsers = await pgClient.query('SELECT COUNT(*) FROM users');
    const jsonUsers = jsonDb.users.length;
    console.log('Users:');
    console.log('  PostgreSQL: ' + pgUsers.rows[0].count);
    console.log('  JSON:       ' + jsonUsers);
    console.log('  Match:      ' + (pgUsers.rows[0].count == jsonUsers ? 'YES' : 'NO'));
    
    // Validate Groups
    const pgGroups = await pgClient.query('SELECT COUNT(*) FROM groups');
    const jsonGroups = jsonDb.groups.length;
    console.log('Groups:');
    console.log('  PostgreSQL: ' + pgGroups.rows[0].count);
    console.log('  JSON:       ' + jsonGroups);
    console.log('  Match:      ' + (pgGroups.rows[0].count == jsonGroups ? 'YES' : 'NO'));
    
    await pgClient.end();
}

validateSync().catch(console.error);

USAGE:
node /var/www/html/main/validate-sync.js

================================================================================
7. POSTGRESQL SLOW QUERY MONITORING
================================================================================

SETUP:
1. Edit postgresql.conf:
   sudo nano /etc/postgresql/16/main/postgresql.conf
   
2. Add/update settings:
   log_min_duration_statement = 100  # Log queries slower than 100ms
   log_line_prefix = '%t [%p]: '
   log_statement = 'all'
   
3. Restart PostgreSQL:
   sudo systemctl restart postgresql

4. Monitor slow queries:
   tail -f /var/log/postgresql/postgresql-16-main.log | grep "duration:"

================================================================================
8. ROLLBACK PROCEDURES
================================================================================

IF DUAL-WRITE CAUSES ISSUES:

1. Stop API:
   pm2 stop latanda-api-fixed

2. Restore backup:
   cp integrated-api-complete-95-endpoints.BACKUP-BEFORE-DUALWRITE-REGISTER \
      integrated-api-complete-95-endpoints.js

3. Restart API:
   pm2 restart latanda-api-fixed

4. Verify:
   pm2 logs latanda-api-fixed --lines 20
   curl http://localhost:3002/api/health

5. Investigate error:
   Check logs for error messages
   Review code changes
   Test in staging environment

================================================================================
9. SUCCESS METRICS
================================================================================

WEEK 3-4 GOALS:
- 4 critical endpoints using dual-write
- Data consistency validation script working
- PostgreSQL slow query monitoring active
- Zero downtime deployments
- < 1% error rate

DATABASE SCORE TARGET:
Current:  1.75/2 (87.5%)
Target:   2/2 (100%)
Impact:   Overall score 41% -> 44%

PERFORMANCE TARGETS:
- POST /api/auth/register: < 50ms
- POST /api/groups: < 50ms
- Data sync validation: < 5 seconds
- Connection pool usage: < 50%

================================================================================
10. NEXT STEPS AFTER WEEK 3-4
================================================================================

WEEK 5-6: Complete remaining endpoints
WEEK 7-8: Remove JSON fallbacks (PostgreSQL primary only)
WEEK 9-10: Performance optimization and indexing
WEEK 11-12: Complete migration, decommission JSON database

================================================================================
